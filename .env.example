# ==========================================
# LLM Provider API Keys
# ==========================================

# OpenAI API (Required for GPT models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API (For Claude models)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Google AI API (For Gemini models)
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# Hugging Face API (For open-source models)
# Get from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your-huggingface-api-key-here

# ==========================================
# LLM Provider & Model Settings
# ==========================================

# Primary provider (openai/anthropic/google/huggingface/ollama)
LLM_PROVIDER=openai

# Model selection based on provider
# OpenAI: gpt-4o-mini-2024-07-18, gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
# Google: gemini-pro, gemini-1.5-pro
LLM_MODEL=gpt-4o-mini-2024-07-18

# ==========================================
# Fine-Tuned Models (Optional)
# ==========================================

# GPT-4o-mini Fine-tuned
# Format: ft:gpt-4o-mini-2024-07-18:your-org:model-name:id
FT_GPT4O_MINI_MODEL=

# Llama-3-8B Fine-tuned (local path or HF model)
FT_LLAMA3_MODEL=

# Gemma-7B Fine-tuned (local path or HF model)
FT_GEMMA_MODEL=

# ==========================================
# Database Configuration
# ==========================================

# SQLite (default - included in repo)
DATABASE_URL=sqlite:///./data/processed/sales.db
DATABASE_TYPE=sqlite

# PostgreSQL (alternative)
# DATABASE_URL=postgresql://user:password@host:5432/dbname
# DATABASE_TYPE=postgresql

# ==========================================
# Server Configuration
# ==========================================

# Backend API port
PORT=8000

# Frontend URL (for CORS)
FRONTEND_URL=http://localhost:3000

# Environment (development/production)
ENVIRONMENT=development

# ==========================================
# Security Settings
# ==========================================

# JWT secret for authentication
JWT_SECRET_KEY=your-secret-key-change-in-production

# Allowed origins for CORS (comma-separated)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8501

# Safety mode (strict/moderate/permissive)
SAFETY_MODE=strict

# Maximum query complexity level (1-10)
MAX_QUERY_COMPLEXITY=5

# Enable role-based access control
ENABLE_RBAC=false

# Read-only mode (only SELECT queries allowed)
READ_ONLY_MODE=true

# ==========================================
# Logging & Monitoring
# ==========================================

# Log level (DEBUG/INFO/WARNING/ERROR)
LOG_LEVEL=INFO

# Enable query logging
ENABLE_QUERY_LOGGING=true

# Enable metrics collection
ENABLE_METRICS=true

# ==========================================
# Rate Limiting
# ==========================================

# Requests per minute
RATE_LIMIT_RPM=60

# ==========================================
# Cache Settings
# ==========================================

# Enable query result caching
ENABLE_CACHE=false

# Cache TTL in seconds
CACHE_TTL=3600

# ==========================================
# Additional Settings
# ==========================================

# Maximum result rows to return
MAX_RESULT_ROWS=1000

# Query timeout in seconds
QUERY_TIMEOUT=30

# ==========================================
# Ollama Settings (For local models)
# ==========================================

# Ollama API endpoint
OLLAMA_API_URL=http://localhost:11434

# Ollama model name
OLLAMA_MODEL=llama3

# ==========================================
# Vector Store Settings (Optional)
# ==========================================

# Enable semantic search
ENABLE_SEMANTIC_SEARCH=false

# Vector store type (faiss/chroma/pinecone)
VECTOR_STORE_TYPE=faiss

# Pinecone API key (if using Pinecone)
PINECONE_API_KEY=your-pinecone-api-key-here

# Pinecone environment
PINECONE_ENVIRONMENT=your-pinecone-environment
