ACID & CIA Metrics for LLM-Based DBMS

Measurement Framework for Database Integrity and Security

1\. Introduction

This document defines comprehensive metrics for measuring ACID
(Atomicity, Consistency, Isolation, Durability) and CIA
(Confidentiality, Integrity, Availability) compliance in the LLM-Based
Database Management System. Each metric includes its mathematical
formula, calculation method, and specific application to the project.

2\. ACID Compliance Metrics

2.1 Atomicity Metrics

Atomicity ensures that each transaction is treated as a single unit that
either completely succeeds or completely fails.

2.1.1 Transaction Success Rate (TSR)

TSR = (T_complete / T_total) × 100%

**Where:** T_complete = Number of fully completed transactions T_total =
Total number of initiated transactions

**Application to Project:**

- Track each SQL query generated by the LLM from initiation to
  completion

- Count queries that execute successfully versus those that fail or are
  rolled back

- Target: ≥ 95% transaction success rate

- Log failed transactions for analysis and model improvement

2.1.2 Rollback Success Rate (RSR)

RSR = (R_success / R_attempted) × 100%

**Where:** R_success = Number of successful rollbacks R_attempted =
Total number of rollback attempts

**Application to Project:**

- When Rule-Based Validator detects errors, trigger transaction rollback

- Measure percentage of successful rollbacks to original state

- Target: 100% rollback success rate

- Test with intentionally malformed queries to verify rollback mechanism

2.2 Consistency Metrics

Consistency ensures that transactions bring the database from one valid
state to another, maintaining all defined rules and constraints.

2.2.1 Constraint Violation Rate (CVR)

CVR = (Q_violation / Q_total) × 100%

**Where:** Q_violation = Number of queries violating database
constraints Q_total = Total number of queries executed

**Application to Project:**

- Monitor queries that violate foreign key, unique, or check constraints

- Track attempts to insert NULL values in NOT NULL columns

- Target: ≤ 2% constraint violation rate

- Rule-Based Validator should catch violations before execution

2.2.2 Data Integrity Score (DIS)

DIS = (1 - E_integrity / T_checks) × 100%

**Where:** E_integrity = Number of integrity check failures T_checks =
Total number of integrity checks performed

**Application to Project:**

- Periodically verify referential integrity across all tables

- Check for orphaned records after DELETE operations

- Validate data type consistency

- Target: ≥ 99.5% data integrity score

2.3 Isolation Metrics

Isolation ensures that concurrent transactions do not interfere with
each other.

2.3.1 Serialization Conflict Rate (SCR)

SCR = (C_conflicts / T_concurrent) × 100%

**Where:** C_conflicts = Number of serialization conflicts detected
T_concurrent = Total number of concurrent transactions

**Application to Project:**

- Monitor conflicts when multiple users query simultaneously

- Track lock wait times and deadlock occurrences

- Target: ≤ 1% serialization conflict rate

- SQLite3\'s default isolation level handles most scenarios

2.3.2 Isolation Level Compliance (ILC)

ILC = (T_isolated / T_total) × 100%

**Where:** T_isolated = Number of properly isolated transactions T_total
= Total number of transactions

**Application to Project:**

- Ensure each query executes at appropriate isolation level

- Prevent dirty reads, non-repeatable reads, and phantom reads

- Target: 100% isolation level compliance

- Test with concurrent read/write operations

2.4 Durability Metrics

Durability ensures that once a transaction is committed, it remains so
even in the event of system failure.

2.4.1 Data Persistence Rate (DPR)

DPR = (D_persisted / D_committed) × 100%

**Where:** D_persisted = Number of committed transactions verified after
system restart D_committed = Total number of committed transactions
before restart

**Application to Project:**

- Perform simulated system crashes during testing

- Verify all committed data remains after restart

- Target: 100% data persistence rate

- SQLite3 write-ahead logging (WAL) ensures durability

2.4.2 Recovery Time Metric (RTM)

RTM = Average(t_recovery_1, t_recovery_2, \..., t_recovery_n)

**Where:** t_recovery_i = Time to recover from failure i n = Number of
recovery tests performed

**Application to Project:**

- Measure time from system crash to full operational state

- Include database recovery and LLM service restart time

- Target: ≤ 30 seconds average recovery time

- Test with different failure scenarios

3\. CIA Security Metrics

3.1 Confidentiality Metrics

Confidentiality ensures that data is accessible only to authorized users
and that unauthorized access is prevented.

3.1.1 SQL Injection Prevention Rate (SIPR)

SIPR = (I_blocked / I_attempted) × 100%

**Where:** I_blocked = Number of injection attempts blocked by validator
I_attempted = Total number of injection attempts detected

**Application to Project:**

- Rule-Based Validator must detect malicious SQL patterns

- Test with OWASP Top 10 SQL injection techniques

- Block queries with: \'; DROP TABLE, UNION SELECT, \-- comments

- Target: 100% injection prevention rate

3.1.2 Unauthorized Access Rate (UAR)

UAR = (A_unauthorized / A_total) × 100%

**Where:** A_unauthorized = Number of unauthorized access attempts
A_total = Total number of access attempts

**Application to Project:**

- Implement user authentication for database access

- Log all access attempts with user credentials

- Detect patterns of unauthorized access attempts

- Target: 0% successful unauthorized access

3.2 Integrity Metrics

Integrity ensures that data is accurate, consistent, and protected from
unauthorized modification.

3.2.1 Query Validation Success Rate (QVSR)

QVSR = (Q_validated / Q_generated) × 100%

**Where:** Q_validated = Number of queries passing all validation checks
Q_generated = Total number of queries generated by LLM

**Application to Project:**

- Validate syntax, logical consistency, and security of every query

- Check for: valid table names, column names, proper JOIN syntax

- Target: ≥ 95% validation success rate

- Low rate indicates need for additional model fine-tuning

3.2.2 Hallucination Detection Rate (HDR)

HDR = (H_detected / Q_generated) × 100%

**Where:** H_detected = Number of queries with hallucinated elements
(non-existent tables/columns) Q_generated = Total number of queries
generated

**Application to Project:**

- Cross-reference generated queries against actual database schema

- Flag queries referencing non-existent tables or columns

- Target: ≤ 2% hallucination detection rate

- Use vector search to prevent schema hallucinations

3.3 Availability Metrics

Availability ensures that the system is operational and accessible when
needed.

3.3.1 System Uptime (SU)

SU = (T_operational / T_total) × 100%

**Where:** T_operational = Time system is fully operational T_total =
Total time in measurement period

**Application to Project:**

- Monitor system availability 24/7

- Track planned and unplanned downtime separately

- Target: ≥ 99.5% uptime (approximately 3.65 hours downtime per month)

- Implement health check endpoints

3.3.2 Average Response Time (ART)

ART = (Σ t_response_i) / n

**Where:** t_response_i = Response time for query i n = Total number of
queries processed

**Application to Project:**

- Measure end-to-end time: user input → SQL generation → validation →
  execution → result

- Include LLM inference time + database query execution time

- Target: ≤ 3 seconds average response time

- Optimize slow queries and consider caching frequent patterns

3.3.3 Service Availability Rate (SAR)

SAR = (R_success / R_total) × 100%

**Where:** R_success = Number of successful query requests R_total =
Total number of query requests

**Application to Project:**

- Track requests that receive valid responses (even if query fails
  validation)

- Distinguish between service unavailable vs. query validation failures

- Target: ≥ 99.9% service availability rate

- Implement load balancing if using multiple LLM instances

4\. Implementation Framework

4.1 Monitoring Infrastructure

- Implement comprehensive logging for all transactions and queries

- Store metrics in separate monitoring database

- Create real-time dashboards for key metrics

- Set up automated alerts for threshold violations

4.2 Testing Protocol

- Conduct weekly metric collection during development phase

- Perform stress testing with concurrent users

- Execute security penetration testing

- Simulate system failures for durability testing

- Test with both valid and adversarial inputs

4.3 Reporting and Analysis

- Generate weekly metric reports

- Analyze trends over time to identify degradation

- Document incidents and their impact on metrics

- Use metrics to guide model fine-tuning iterations

5\. Target Metrics Summary

| **Metric Category** | **Metric Name**               | **Target Value** |
|---------------------|-------------------------------|------------------|
| **Atomicity**       | Transaction Success Rate      | ≥ 95%            |
|                     | Rollback Success Rate         | 100%             |
| **Consistency**     | Constraint Violation Rate     | ≤ 2%             |
|                     | Data Integrity Score          | ≥ 99.5%          |
| **Isolation**       | Serialization Conflict Rate   | ≤ 1%             |
|                     | Isolation Level Compliance    | 100%             |
| **Durability**      | Data Persistence Rate         | 100%             |
|                     | Recovery Time Metric          | ≤ 30 seconds     |
| **Confidentiality** | SQL Injection Prevention Rate | 100%             |
|                     | Unauthorized Access Rate      | 0%               |
| **Integrity**       | Query Validation Success Rate | ≥ 95%            |
|                     | Hallucination Detection Rate  |                  |
| **Availability**    | System Uptime                 | ≥ 99.5%          |
|                     | Average Response Time         | ≤ 3 seconds      |
|                     | Service Availability Rate     | ≥ 99.9%          |

Appendix: LaTeX Formula Code

The following LaTeX code can be used to typeset these formulas in
academic papers or technical documentation:

**% ACID Metrics**

*% Atomicity*

\text{TSR} = \frac{T\_{\text{complete}}}{T\_{\text{total}}} \times 100\\

\text{RSR} = \frac{R\_{\text{success}}}{R\_{\text{attempted}}} \times
100\\

*% Consistency*

\text{CVR} = \frac{Q\_{\text{violation}}}{Q\_{\text{total}}} \times
100\\

\text{DIS} = \left(1 -
\frac{E\_{\text{integrity}}}{T\_{\text{checks}}}\right) \times 100\\

*% Isolation*

\text{SCR} = \frac{C\_{\text{conflicts}}}{T\_{\text{concurrent}}} \times
100\\

\text{ILC} = \frac{T\_{\text{isolated}}}{T\_{\text{total}}} \times 100\\

*% Durability*

\text{DPR} = \frac{D\_{\text{persisted}}}{D\_{\text{committed}}} \times
100\\

\text{RTM} = \frac{1}{n}\sum\_{i=1}\^{n} t\_{\text{recovery}\_i}

**% CIA Metrics**

*% Confidentiality*

\text{SIPR} = \frac{I\_{\text{blocked}}}{I\_{\text{attempted}}} \times
100\\

\text{UAR} = \frac{A\_{\text{unauthorized}}}{A\_{\text{total}}} \times
100\\

*% Integrity*

\text{QVSR} = \frac{Q\_{\text{validated}}}{Q\_{\text{generated}}} \times
100\\

\text{HDR} = \frac{H\_{\text{detected}}}{Q\_{\text{generated}}} \times
100\\

*% Availability*

\text{SU} = \frac{T\_{\text{operational}}}{T\_{\text{total}}} \times
100\\

\text{ART} = \frac{\sum\_{i=1}\^{n} t\_{\text{response}\_i}}{n}

\text{SAR} = \frac{R\_{\text{success}}}{R\_{\text{total}}} \times 100\\

*Note: Enclose these formulas in \$ \$ for inline mode or \$\$ \$\$ for
display mode in your LaTeX document.*
